第十三天
       今天很烦躁  浑身没劲儿
       
       
    昨天没有做完的：
             卷积神经网络--Pooling 下采样--Pooling层需要做的仅仅是将误差项传递到上一层，而没有梯度的计算。
             卷积操作也叫互相关
             反向传播算法的过程
                       1.前向计算神经元的输出值
                       2.反向计算每个神经元的误差项，实际上是损失函数对神经元的加权输入的偏导数
                       3.计算每个神经元连接权重的梯度
                       4.根据梯度下降更新每个权重值
             排序算法
                    交换排序--1.冒泡排序  2.快速排序
                    插入排序--1.简单插入排序  2.希尔排序--缩小增量排序
                    选择排序--1.简单选择排序 2.堆排序--即子结点的键值或索引总是小于（或者大于）它的父节点。
                    归并排序--1.二路归并排序  2.多路归并排序
                    
                    
                    
    机器学习基础--XGBoost--XGBoost 是改进的梯度提升(GB)算法
                 GB为基于残差的学习  负梯度的学习方向
                XGBoost是根据一阶导数和二阶导数，迭代生成基学习器，相加更新学习器
                
                Box–Muller 变换
                
                降维--PCA  SVD  t-SNE
    tensorflow--Word2Vec
                将高维词向量嵌入到一个低维空间--CBOW(Continuous Bag-of-Words)适合小型数据集   Skip-Gram在大型语料中表现更好
                
                    
